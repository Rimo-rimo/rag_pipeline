{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import dotenv\n",
    "import nest_asyncio\n",
    "dotenv.load_dotenv()\n",
    "import requests\n",
    "import json\n",
    "from glob import glob\n",
    "import time\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from urllib.parse import unquote\n",
    "from collections import defaultdict\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from pdf2image import convert_from_path\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "from PIL import Image, ImageDraw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HTML \n",
    "* 하나의 PDF로 부터 나온 html tag는, id값이 1씩 increase 하도록 후처리\n",
    "* 추후 해당 id를 활용해, json으로 부터 dounding_box와 page를 가져올 예정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# html 파일을 읽어서, id 값을 수정하는 함수\n",
    "def change_html_tag_id(html_path, save_path):\n",
    "    html = open(html_path).read()\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    re = 0\n",
    "    for tag in soup.find_all():\n",
    "        if tag.get('id'):\n",
    "            tag['id'] = re\n",
    "            re += 1\n",
    "    with open(save_path, 'w') as f:    \n",
    "        f.write(str(soup))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_paths = glob(\"../data/nursing/nursing_html/*\")\n",
    "for html_path in html_paths:\n",
    "    file_name = os.path.basename(html_path)\n",
    "    change_html_tag_id(html_path, f\"../data/nursing/nursing_html2/{file_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JSON\n",
    "* Document Parser로 부터 저장된 JSON 파일을 PDF 단위로 결합\n",
    "* 결합시, id는 0부터 시작하여 HTML의 파일과 동일하게 매칭"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_post_process(file_paths, save_folder_path):\n",
    "    file_names = list(set([os.path.basename(file_path).split(\".pdf\")[0] for file_path in file_paths]))\n",
    "    re = defaultdict(list)\n",
    "\n",
    "    # 파일 이름이 같은 것들을 묶어준다.\n",
    "    for file_name in file_names:\n",
    "        for file_path in file_paths:\n",
    "            if file_name in file_path:\n",
    "                re[file_name].append(file_path)\n",
    "    \n",
    "    # 정렬 해 준다.\n",
    "    for file_name in re:\n",
    "        re[file_name] = sorted(re[file_name])\n",
    "    \n",
    "    for file_name in re:\n",
    "        re_json = {\"elements\":[]}\n",
    "        for file_path in re[file_name]:\n",
    "            with open(file_path, \"r\") as f:\n",
    "                data = json.load(f)\n",
    "                re_json[\"elements\"].extend(data[\"elements\"])\n",
    "        id_ = 0\n",
    "        for r in re_json[\"elements\"]:\n",
    "            r[\"id\"] = id_\n",
    "            id_ += 1\n",
    "            for b in r[\"bounding_box\"]:\n",
    "                b[\"x\"] = b[\"x\"]/1362\n",
    "                b[\"y\"] = b[\"y\"]/1776\n",
    "        \n",
    "        with open(os.path.join(save_folder_path, file_name+\".json\"), 'w') as f:\n",
    "            json.dump(re_json, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_post_process(glob(\"../data/nursing/nursing_downloads/*.json\"), \"../data/nursing/nursing_json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDF to PNG\n",
    "* PDF 파일을 PNG 이미지로 변환\n",
    "* 형식 : 파일이름_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_paths = glob(\"../data/nursing/*.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/nursing/22장 신경계장애 대상자간호-(1).pdf',\n",
       " '../data/nursing/18장 요로계 장애 대상자 간호.pdf',\n",
       " '../data/nursing/14장 호흡기장애 대상자 간호-(2).pdf',\n",
       " '../data/nursing/17장 혈액계 장애 대상자 간호.pdf',\n",
       " '../data/nursing/21장 근골격계 장애.pdf',\n",
       " '../data/nursing/20장 유방장애 대상자 간호.pdf',\n",
       " '../data/nursing/27장 화상간호.pdf',\n",
       " '../data/nursing/25장 청각과 평형장애 대상자 간호.pdf',\n",
       " '../data/nursing/30 판권.pdf',\n",
       " '../data/nursing/26장 피부장애 대상자 간호.pdf',\n",
       " '../data/nursing/16장 혈관장애 대상자 간호.pdf',\n",
       " '../data/nursing/19장 남성 생식기계 대상자 간호.pdf',\n",
       " '../data/nursing/14장 호흡기장애 대상자 간호-(1).pdf',\n",
       " '../data/nursing/22장 신경계장애 대상자간호-(2).pdf',\n",
       " '../data/nursing/00 도입부(하권).pdf',\n",
       " '../data/nursing/23장 내분비장애 대상자 간호.pdf',\n",
       " '../data/nursing/24장 시각장애 대상자 간호.pdf',\n",
       " '../data/nursing/15장 심장장애 대상자 간호-(2).pdf',\n",
       " '../data/nursing/15장 심장장애 대상자 간호-(1).pdf']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [09:26<00:00, 29.82s/it]\n"
     ]
    }
   ],
   "source": [
    "for pdf_path in tqdm(pdf_paths):\n",
    "    images = convert_from_path(pdf_path, dpi=150)\n",
    "    file_name = os.path.basename(pdf_path).split(\".pdf\")[0]\n",
    "    \n",
    "    if not os.path.exists(f\"../data/nursing/nursing_images/{file_name}\"):\n",
    "        os.makedirs(f\"../data/nursing/nursing_images/{file_name}\")\n",
    "\n",
    "    for i, image in enumerate(images):\n",
    "        image.save(f\"../data/nursing/nursing_images/{file_name}/{i}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = convert_from_path(\"/home/livin/rag_pipeline/AutoRAG/data/nursing/14장 호흡기장애 대상자 간호-(1).pdf\", dpi=150)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_pipeline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
