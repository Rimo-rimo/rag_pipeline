{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "import os\n",
    "import sys\n",
    "import dotenv\n",
    "import nest_asyncio\n",
    "dotenv.load_dotenv()\n",
    "import requests\n",
    "import json\n",
    "from glob import glob\n",
    "import time\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from urllib.parse import unquote"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = api_key = os.getenv(\"UPSTAGE_API_KEY\")\n",
    "file_name_list = glob(\"../data/nursing/*.pdf\")\n",
    "headers = {\"Authorization\": f\"Bearer {api_key}\"}\n",
    "document_parser_url = \"https://api.upstage.ai/v1/document-ai/async/document-parse\"\n",
    "check_url = \"https://api.upstage.ai/v1/document-ai/requests\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# document_file_name,request_id, download_url 이 컬럼인 df를 만들어서 csv로 저장 하는 로직 구현\n",
    "df = []\n",
    "for file_name in tqdm(file_name_list):\n",
    "    try:\n",
    "        print(f\"{file_name} - Start!\")\n",
    "        files = {\"document\": open(file_name, \"rb\")}\n",
    "        data = {\n",
    "            \"ocr\": \"force\",\n",
    "            \"output_formats\": '[\"markdown\", \"html\", \"text\"]'\n",
    "            }\n",
    "        api_response = requests.post(document_parser_url, headers=headers, files=files, data=data)\n",
    "        while True:\n",
    "            check_response = requests.get(os.path.join(check_url, api_response.json()[\"request_id\"]), headers=headers)\n",
    "            is_completed = False\n",
    "            for batch in check_response.json()[\"batches\"]:\n",
    "                if batch[\"status\"] == \"completed\":\n",
    "                    is_completed = True\n",
    "                else:\n",
    "                    is_completed = False\n",
    "                    break\n",
    "            if is_completed:\n",
    "                print(f\"{file_name} - Completed!\")\n",
    "                break\n",
    "            else:\n",
    "                time.sleep(10)\n",
    "        for batch in check_response.json()[\"batches\"]:\n",
    "            df.append([file_name, api_response.json()[\"request_id\"], batch])\n",
    "        print(f\"==============================================\")\n",
    "    except Exception as e:\n",
    "        print(f\"{file_name} - error\")\n",
    "        print(e)\n",
    "        continue\n",
    "\n",
    "# df를 csv로 저장\n",
    "df = pd.DataFrame(df, columns=[\"document_file_name\", \"request_id\", \"batch\"])\n",
    "df.to_csv(\"../data/nursing/parse_result_3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check request_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_response = requests.get(check_url, headers=headers).json()[\"requests\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Downloading 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(url, folder_path):\n",
    "    # 폴더가 존재하지 않으면 생성\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "\n",
    "    # 파일 다운로드 시작\n",
    "    response = requests.get(url, stream=True)\n",
    "    response.raise_for_status()  # 다운로드가 실패했는지 확인\n",
    "\n",
    "    file_name = url.split(\"/\")[-1]\n",
    "    # 파일명을 한글 인코딩을 고려하여 디코딩\n",
    "    file_name = unquote(file_name).split(\"?\")[0]\n",
    "\n",
    "\n",
    "    # 저장 경로 지정\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "    # 파일 저장\n",
    "    with open(file_path, 'wb') as f:\n",
    "        for chunk in response.iter_content(chunk_size=8192):\n",
    "            if chunk:\n",
    "                f.write(chunk)\n",
    "    print(f\"File saved at {file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Downloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"./downloads\"\n",
    "\n",
    "for check_response_i in check_response:\n",
    "    if check_response_i[\"status\"] == \"completed\":\n",
    "        batch_results = requests.get(os.path.join(check_url, check_response_i[\"id\"]), headers=headers).json()[\"batches\"]\n",
    "        for batch_result in batch_results:\n",
    "            download_file(batch_result[\"download_url\"], folder_path)\n",
    "        print(\"Completed\")\n",
    "    else:\n",
    "        print(\"Not completed yet\")\n",
    "        continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_pipeline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
