{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'FlagEmbedding'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpymilvus\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MilvusClient, Collection, connections, DataType, CollectionSchema, FieldSchema\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpymilvus\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreranker\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BGERerankFunction\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mFlagEmbedding\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FlagReranker\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'FlagEmbedding'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import numpy as np\n",
    "import json\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "from pymilvus import model\n",
    "from pymilvus import MilvusClient, Collection, connections, DataType, CollectionSchema, FieldSchema\n",
    "from pymilvus.model.reranker import BGERerankFunction\n",
    "\n",
    "from FlagEmbedding import FlagReranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding 모델 Load\n",
    "def get_embedding_model(model_name = \"BAAI/bge-m3\", batch_size= 64, device = \"cuda:0\"):\n",
    "    bge_m3_ef = model.hybrid.BGEM3EmbeddingFunction(\n",
    "        model_name= model_name,\n",
    "        batch_size = batch_size,\n",
    "        device = device,\n",
    "        return_dense = True,\n",
    "        return_sparse = False,\n",
    "        return_colbert_vecs = False,\n",
    "    )\n",
    "    return bge_m3_ef\n",
    "\n",
    "# # BGE Reranker 모델 Load\n",
    "# def get_reranker_model(model_path = \"./models/kw_3_easy_train\",\n",
    "#                        device = \"cuda:0\"):\n",
    "#     bge_rf = BGERerankFunction(\n",
    "#         model_name=model_path,\n",
    "#         device=device,\n",
    "#         batch_size=32,\n",
    "#     )\n",
    "#     return bge_rf\n",
    "\n",
    "# # 검색 result를 tsv 형태로 저장\n",
    "# def save_to_tsv(result, output_path):\n",
    "#     result_df = pd.DataFrame(result)\n",
    "#     result_df.to_csv(output_path, sep='\\t', index=False)\n",
    "#     print(\"Successfully Saved!\")\n",
    "\n",
    "def get_vector_search_result(client, bge_m3_ef, query, top_n = 100):\n",
    "\n",
    "    query_vectors = bge_m3_ef.encode_queries([query])[\"dense\"]\n",
    "    candidate = client.search(\n",
    "        collection_name=\"msmarco_bgem3\",  # target collection\n",
    "        data=query_vectors,  # query vectors\n",
    "        limit=top_n,  # number of returned entities\n",
    "        output_fields=[\"pid\",\"text\"],\n",
    "        anns_field=\"dense_vector\",\n",
    "    )\n",
    "    candidate_passages = [i[\"entity\"][\"text\"] for i in candidate[0]]\n",
    "    candidate_pids = np.array([i[\"entity\"][\"pid\"] for i in candidate[0]])\n",
    "\n",
    "    return candidate_pids, candidate_passages\n",
    "\n",
    "# def get_reranker_result(query, candidate_passages, top_n = 100):\n",
    "#     top_k = bge_rf(\n",
    "#             query=query,\n",
    "#             documents=candidate_passages,\n",
    "#             top_k=top_n,\n",
    "#         )\n",
    "#     return top_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df5028e98e1046b7a2f70307012f3d43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 30 files:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# BGE-M3\n",
    "bge_m3_ef = get_embedding_model()\n",
    "\n",
    "# BGE Reranker\n",
    "# bge_rf = get_reranker_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VectorDB에 클라이언트 연결\n",
    "client = MilvusClient()\n",
    "client.load_collection(\"wiki_ko_bgem3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a543cdab1e5a4f13a2e08d5e16698934",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 30 files:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pymilvus.model.hybrid import BGEM3EmbeddingFunction\n",
    "\n",
    "bge_m3_ef = BGEM3EmbeddingFunction(\n",
    "    model_name='BAAI/bge-m3', # Specify the model name\n",
    "    device='cuda', # Specify the device to use, e.g., 'cpu' or 'cuda:0'\n",
    "    use_fp16=False # Specify whether to use fp16. Set to `False` if `device` is `cpu`.\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "M3Embedder.encode() missing 1 required positional argument: 'queries'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m queries \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen was artificial intelligence founded\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m      2\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhere was Alan Turing born?\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m----> 4\u001b[0m query_embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mbge_m3_ef\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode_queries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqueries\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/auto_rag/lib/python3.11/site-packages/milvus_model/hybrid/bge_m3.py:102\u001b[0m, in \u001b[0;36mBGEM3EmbeddingFunction.encode_queries\u001b[0;34m(self, queries)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mencode_queries\u001b[39m(\u001b[38;5;28mself\u001b[39m, queries: List[\u001b[38;5;28mstr\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict:\n\u001b[0;32m--> 102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_encode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqueries\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/auto_rag/lib/python3.11/site-packages/milvus_model/hybrid/bge_m3.py:83\u001b[0m, in \u001b[0;36mBGEM3EmbeddingFunction._encode\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_encode\u001b[39m(\u001b[38;5;28mself\u001b[39m, texts: List[\u001b[38;5;28mstr\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict:\n\u001b[0;32m---> 83\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_encode_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m     results \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_encode_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreturn_dense\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: M3Embedder.encode() missing 1 required positional argument: 'queries'"
     ]
    }
   ],
   "source": [
    "queries = [\"When was artificial intelligence founded\", \n",
    "           \"Where was Alan Turing born?\"]\n",
    "\n",
    "query_embeddings = bge_m3_ef.encode_queries(queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1324/1324 [18:54<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully Saved!\n"
     ]
    }
   ],
   "source": [
    "# 19분 소요\n",
    "result = []\n",
    "error_list = []\n",
    "\n",
    "for i in tqdm(range(len(test_qid))):\n",
    "    try:\n",
    "        qid = test_qid[i]\n",
    "        query = unique_query[unique_query[\"qid\"] == qid][\"query\"].tolist()[0]\n",
    "        candidate_pids, candidate_passages = get_vector_search_result(client, query, 100)\n",
    "        top_k = get_reranker_result(query, candidate_passages, 100)\n",
    "\n",
    "        for n,k in enumerate(top_k):\n",
    "            result.append([qid, candidate_pids[k.index], n+1])\n",
    "\n",
    "    except:\n",
    "        error_list.append(qid)\n",
    "        print(qid)\n",
    "\n",
    "output_path = \"./result/bgem3_reranker.tsv\"\n",
    "save_to_tsv(result, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MRR@100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BGEM3 + Reranker\n",
      "################################\n",
      "# MRR @100: 0.4392646840231909 #\n",
      "################################\n"
     ]
    }
   ],
   "source": [
    "print(\"BGEM3 + Reranker\")\n",
    "!python ms_marco_eval.py \\\n",
    "./data/test_qrels.tsv \\\n",
    "./result/bgem3_reranker.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "auto_rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
